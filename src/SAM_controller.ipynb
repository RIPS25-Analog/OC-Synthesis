{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef922d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import SAM\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics.data.utils import visualize_image_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126924a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class folders should be organized as follows:\n",
    "#\n",
    "# raw/\n",
    "# └── screwdriver_kaggle/\n",
    "#    ├── screwdriver/\n",
    "#    │   ├── images/\n",
    "#    │   │   ├── 1.jpg\n",
    "#    │   │   └── ...\n",
    "#    │   ├── labels/\n",
    "#    │   │   ├── 1.txt\n",
    "#    │   │   └── ...\n",
    "#    │   ├── masks/\n",
    "#    │   │   ├── 1_mask.png\n",
    "#    │   │   └── ...  \n",
    "#    ├── hammer/\n",
    "#    │   └── .../\n",
    "#    ├── .../\n",
    "#    └── classes.txt\n",
    "\n",
    "# Darknet files should have the following format:\n",
    "# class_index x_center y_center width height\n",
    "#\n",
    "# e.g.\n",
    "# 0 0.5 0.5 0.2 0.2\n",
    "\n",
    "# classes.txt should contain the class names, one per line:\n",
    "# e.g.\n",
    "# screwdriver\n",
    "# hammer\n",
    "# ...\n",
    "\n",
    "project_name = 'kaggle_v0'\n",
    "object_classes = ['screwdriver', 'hammer']\n",
    "class_dirs = [f'../data/raw/{project_name}/{object_class}/' for object_class in object_classes]\n",
    "output_dirs = [f'../data/raw/{project_name}/cut_and_paste_root/{object_class}/' for object_class in object_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4b13f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(input_dir, output_dir, size=(640//3, 480//3)):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for img_file in glob.glob(os.path.join(input_dir, '*.jpg')):\n",
    "        img = Image.open(img_file)\n",
    "        img = img.resize(size, Image.LANCZOS)\n",
    "        img.save(os.path.join(output_dir, os.path.basename(img_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_dir in class_dirs:\n",
    "    resize_images(os.path.join(class_dir, 'images'), os.path.join(class_dir, 'images_resized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_darknet_bboxes(bbox_path, image_width, image_height):\n",
    "\t\"\"\"Read bounding boxes from darknet format file and convert to pixel coordinates\"\"\"\n",
    "\tbboxes = []\n",
    "\t\n",
    "\twith open(bbox_path, 'r') as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tparts = line.strip().split()\n",
    "\t\t\tassert len(parts) == 5, f\"Invalid bbox line: {line.strip()}\"\n",
    "\t\t\t\n",
    "\t\t\t# Darknet format: class_id x_center y_center width height (normalized)\n",
    "\t\t\tclass_id = int(parts[0])\n",
    "\t\t\tx_center = float(parts[1])\n",
    "\t\t\ty_center = float(parts[2])\n",
    "\t\t\twidth = float(parts[3])\n",
    "\t\t\theight = float(parts[4])\n",
    "\t\t\t\n",
    "\t\t\t# Convert from normalized coordinates to pixel coordinates\n",
    "\t\t\tx_center_px = x_center * image_width\n",
    "\t\t\ty_center_px = y_center * image_height\n",
    "\t\t\twidth_px = width * image_width\n",
    "\t\t\theight_px = height * image_height\n",
    "\t\t\t\n",
    "\t\t\t# Convert to x1, y1, x2, y2 format\n",
    "\t\t\tx1 = int(x_center_px - width_px / 2)\n",
    "\t\t\ty1 = int(y_center_px - height_px / 2)\n",
    "\t\t\tx2 = int(x_center_px + width_px / 2)\n",
    "\t\t\ty2 = int(y_center_px + height_px / 2)\n",
    "\t\t\t\n",
    "\t\t\t# Ensure coordinates are within image bounds\n",
    "\t\t\tx1 = max(0, min(x1, image_width - 1))\n",
    "\t\t\ty1 = max(0, min(y1, image_height - 1))\n",
    "\t\t\tx2 = max(0, min(x2, image_width - 1))\n",
    "\t\t\ty2 = max(0, min(y2, image_height - 1))\n",
    "\t\t\t\n",
    "\t\t\tbboxes.append([x1, y1, x2, y2])\n",
    "\n",
    "\treturn bboxes\n",
    "\n",
    "def segment_images_from_folder_bbox(class_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Segments images in the specified folder using the SAM model with bbox information.\n",
    "    Assumes class_dir contains two folders: 'images_resized' and 'labels'.\n",
    "    Each image in 'images_resized' should have a corresponding label file in 'labels' with\n",
    "    bounding box information in the format: x y w h (where x, y are the\n",
    "    top-left corner coordinates and w, h are the width and height of the bounding box).\n",
    "    \"\"\"\n",
    "    model = SAM(\"sam2.1_l.pt\")\n",
    "\n",
    "    for image_path, bbox_path in list(zip(sorted(glob.glob(os.path.join(class_dir, 'images', '*'))), \n",
    "                                          sorted(glob.glob(os.path.join(class_dir, 'labels', '*.txt'))))):\n",
    "        image_dimensions = cv2.imread(image_path).shape\n",
    "        bboxes = read_darknet_bboxes(bbox_path, image_dimensions[1], image_dimensions[0])\n",
    "        \n",
    "        # Predict segmentation using the SAM model with bounding box\n",
    "        results = model(image_path, bboxes=bboxes)\n",
    "        # visualize_image_annotations(image_path, bbox_path, output_dir)\n",
    "        for result in results:\n",
    "            # Access the masks\n",
    "            masks = results[0].masks\n",
    "\n",
    "            # Assuming single class segmentation for simplicity, adjust as needed\n",
    "            mask = masks[0].data.squeeze().cpu().numpy()  # For multi-class, iterate over masks\n",
    "            mask = mask.astype(np.uint8) # Convert mask to uint8 if needed)\n",
    "            mask = cv2.resize(mask, (image_dimensions[1], image_dimensions[0]))\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (image_dimensions[1], image_dimensions[0]))\n",
    "            \n",
    "            # Negate the mask and mask the image\n",
    "            negative_mask = 1-mask\n",
    "            negative_image = cv2.bitwise_not(image)\n",
    "            negative_image = cv2.bitwise_and(negative_image, negative_image, mask=mask)\n",
    "            masked_image = cv2.bitwise_not(negative_image)\n",
    "            \n",
    "            # Uncomment to see the negated masks\n",
    "            # plt.imshow(negative_mask, cmap='gray')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # Uncomment to plot the masked images\n",
    "            # plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            os.mkdir(output_dir) if not os.path.exists(output_dir) else None\n",
    "            for subdir in ['images', 'masks', 'labels']:\n",
    "            # Create subdirectories if they do not exist\n",
    "                subdir_path = os.path.join(output_dir, subdir)\n",
    "                if not os.path.exists(subdir_path): \n",
    "                    os.mkdir(subdir_path)\n",
    "            \n",
    "            cv2.imwrite(os.path.join(output_dir, 'images', os.path.basename(image_path)), image)\n",
    "            # cv2.imwrite(os.path.join(output_dir, os.path.basename(image_path).split('.')[0] + '_masked.jpg'), masked_image)\n",
    "            cv2.imwrite(os.path.join(output_dir, 'masks', os.path.basename(image_path).split('.')[0] + '_mask.png'), negative_mask*255)\n",
    "            os.system(f\"cp {bbox_path} {os.path.join(output_dir, 'labels/')}\")\n",
    "            os.system(f\"cp \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97bbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/053e6bbb-40f916dd-8a37-43d1-ae0f-8466096ea779.jpg: 1024x1024 1 0, 222.4ms\n",
      "Speed: 4.7ms preprocess, 222.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/05c2f1ad-4f3c093b-5186-483c-a5ed-f1c1b379dcb5.jpg: 1024x1024 1 0, 216.9ms\n",
      "Speed: 6.1ms preprocess, 216.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/1582021c-6a5b5593-e15a-4beb-8d2c-e71ab1f8aaf9.jpg: 1024x1024 1 0, 217.0ms\n",
      "Speed: 5.8ms preprocess, 217.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/18d1f472-ed195d37-aeac-4039-8113-5c49affa83b8.png: 1024x1024 1 0, 216.9ms\n",
      "Speed: 6.1ms preprocess, 216.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/190e8970-6cf319d6-3a8f-4669-a547-f7e82aa307a7.png: 1024x1024 1 0, 216.6ms\n",
      "Speed: 4.5ms preprocess, 216.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/1dd5cfb4-8391b913-2f25-4020-ba5b-2c8dcbd91bfc.jpg: 1024x1024 1 0, 216.1ms\n",
      "Speed: 5.3ms preprocess, 216.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/1f323682-5f56e0ed-20ba-4315-a6cd-6bc53018d597.jpg: 1024x1024 1 0, 217.4ms\n",
      "Speed: 6.1ms preprocess, 217.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/24da38b1-e22f9aac-ef56-4468-b31e-f4d46823d8ec.jpg: 1024x1024 1 0, 217.2ms\n",
      "Speed: 6.6ms preprocess, 217.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/2c4d9b25-1bad205e-0cdb-4fb7-8952-c60b146ea355.png: 1024x1024 1 0, 217.6ms\n",
      "Speed: 5.8ms preprocess, 217.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/2ce57077-7cfb0168-6991-4ff2-9893-2289e74afc1d.jpeg: 1024x1024 1 0, 216.9ms\n",
      "Speed: 5.8ms preprocess, 216.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/2e03bd5a-95e04b5f-7717-4cfc-8be4-1afb46658c83.jpg: 1024x1024 1 0, 218.5ms\n",
      "Speed: 6.2ms preprocess, 218.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/314efdef-07c01540-f591-4ddf-a1b7-b7a21912e2d7.jpg: 1024x1024 1 0, 218.2ms\n",
      "Speed: 6.2ms preprocess, 218.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/35221b6d-224a9fad-bf25-4d99-a2eb-37ad177dadea.jpg: 1024x1024 1 0, 217.3ms\n",
      "Speed: 4.4ms preprocess, 217.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/35f643d3-f6373cbc-ab88-454f-b386-e0843be187b4.jpeg: 1024x1024 1 0, 217.2ms\n",
      "Speed: 4.0ms preprocess, 217.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/3657bbde-071c74f0-202f-4c88-94ef-f50650492181.jpg: 1024x1024 1 0, 217.2ms\n",
      "Speed: 6.4ms preprocess, 217.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/38d181ec-5ea7acb4-506b-466f-a32e-51d247c7a6e8.jpg: 1024x1024 1 0, 1 1, 218.2ms\n",
      "Speed: 5.3ms preprocess, 218.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/3f8fd847-52784079-784c-4ff0-848a-b9072d934c41.jpg: 1024x1024 1 0, 217.2ms\n",
      "Speed: 6.6ms preprocess, 217.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/445728c5-a42af15f-aea0-43c8-93ca-633a39898587.png: 1024x1024 1 0, 217.2ms\n",
      "Speed: 5.4ms preprocess, 217.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/4c7d5e7e-8cfedefc-da5b-4e47-8579-3118531bbf57.jpg: 1024x1024 1 0, 1 1, 217.6ms\n",
      "Speed: 5.5ms preprocess, 217.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/4c9e2c96-4848641a-10bc-4336-89dc-1f46a8867ac4.png: 1024x1024 1 0, 217.3ms\n",
      "Speed: 4.2ms preprocess, 217.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/5718288b-5489db7f-f14c-432c-9325-d9de83049e7d.png: 1024x1024 1 0, 217.3ms\n",
      "Speed: 5.7ms preprocess, 217.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/5913fdfb-23f868ea-f7fc-4e49-b218-f69649c306c3.jpg: 1024x1024 1 0, 1 1, 217.5ms\n",
      "Speed: 3.7ms preprocess, 217.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/5ed11573-aa3f75ce-422b-46a5-9621-b7a0e05d7152.jpg: 1024x1024 1 0, 217.9ms\n",
      "Speed: 6.2ms preprocess, 217.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/612c49ac-9683a7f7-97c6-43be-8ee2-e369347adc6b.jpg: 1024x1024 1 0, 217.4ms\n",
      "Speed: 4.4ms preprocess, 217.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/613861e0-7911e6a6-f4c1-4141-8b09-04e3668cb82a.jpg: 1024x1024 1 0, 1 1, 218.4ms\n",
      "Speed: 4.2ms preprocess, 218.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/656fe396-783ed844-09e4-4b0d-9daf-7f6bb8df2b7d.jpg: 1024x1024 1 0, 217.3ms\n",
      "Speed: 4.5ms preprocess, 217.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/671e4852-98e4048d-14bd-446b-8ece-e6b50abd958d.jpg: 1024x1024 1 0, 217.8ms\n",
      "Speed: 5.5ms preprocess, 217.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/6b8570f8-044ba734-619e-4445-9dd6-4a31510f45c2.jpg: 1024x1024 1 0, 218.1ms\n",
      "Speed: 6.3ms preprocess, 218.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/6d66b425-8dcea198-702b-46c9-add3-c4924c28eb23.jpg: 1024x1024 1 0, 217.7ms\n",
      "Speed: 4.8ms preprocess, 217.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/6dbb8dcc-a85bb352-fca2-4ed4-b24c-277065d614a8.jpg: 1024x1024 1 0, 218.0ms\n",
      "Speed: 6.3ms preprocess, 218.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/6f6caa86-62141ed4-5940-4810-8df3-fe6148e3f2cb.jpg: 1024x1024 1 0, 1 1, 218.8ms\n",
      "Speed: 5.6ms preprocess, 218.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/7112214f-2ce64707-a3cc-4596-949b-291374a0c69f.jpg: 1024x1024 1 0, 218.2ms\n",
      "Speed: 4.8ms preprocess, 218.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/7167a55d-6916f154-a822-4e3d-91c4-e47f5a3df698.jpg: 1024x1024 1 0, 217.8ms\n",
      "Speed: 4.3ms preprocess, 217.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/72a9ddc5-5004632d-249e-4121-9aa3-ede683ecaaf2.jpg: 1024x1024 1 0, 1 1, 218.7ms\n",
      "Speed: 5.3ms preprocess, 218.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/73922490-63d9acef-a66a-46c6-8ba6-97d24267c630.jpg: 1024x1024 1 0, 218.2ms\n",
      "Speed: 6.2ms preprocess, 218.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/768b47ec-09de8d80-322b-4998-b600-9effd1c6c89c.jpg: 1024x1024 1 0, 218.2ms\n",
      "Speed: 6.2ms preprocess, 218.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/7930f342-389b2e95-e3ff-44dd-9ecc-7f81c28aa7a7.jpg: 1024x1024 1 0, 218.3ms\n",
      "Speed: 4.3ms preprocess, 218.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/7f2bb814-f1ece248-2fb2-4a8b-a5e2-c774547b71cc.jpg: 1024x1024 1 0, 218.4ms\n",
      "Speed: 6.7ms preprocess, 218.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/80159b66-f5f7c23b-254b-4c1a-b4d7-a649f8fb6dd4.jpg: 1024x1024 1 0, 218.4ms\n",
      "Speed: 5.8ms preprocess, 218.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/82d8c17f-43df566b-cdbf-4c7a-b5bb-1f1cb7544c43.jpg: 1024x1024 1 0, 218.9ms\n",
      "Speed: 4.8ms preprocess, 218.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/83501346-51ed876f-ebf8-4e1d-8b8f-bed7b097b306.jpg: 1024x1024 1 0, 218.5ms\n",
      "Speed: 5.7ms preprocess, 218.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/873635c6-45f069ff-ceee-4e38-8c2f-c43403d16771.png: 1024x1024 1 0, 218.4ms\n",
      "Speed: 6.1ms preprocess, 218.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/8cd79be9-d41b3caf-c606-49a9-ba34-fcf77a571d51.png: 1024x1024 1 0, 218.1ms\n",
      "Speed: 5.2ms preprocess, 218.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/900328ab-8270086f-2078-4986-bbe6-4e90cc801b37.jpg: 1024x1024 1 0, 218.4ms\n",
      "Speed: 6.0ms preprocess, 218.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/91c2c35f-60ed741f-1197-4d20-8f53-c30015d35ac6.jpg: 1024x1024 1 0, 218.9ms\n",
      "Speed: 4.3ms preprocess, 218.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/97c916ec-54faca62-f61f-44c3-af2b-5fca8e466d73.jpg: 1024x1024 1 0, 218.8ms\n",
      "Speed: 6.1ms preprocess, 218.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/9914dd82-bd2b93ff-5337-4002-8b3a-feefa8d15264.jpg: 1024x1024 1 0, 218.7ms\n",
      "Speed: 4.3ms preprocess, 218.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/9b5cb123-2786a675-2dc5-4063-842f-89976f8d3db3.jpg: 1024x1024 1 0, 218.3ms\n",
      "Speed: 6.0ms preprocess, 218.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/9d8ad408-357c1722-9a63-4907-932a-30ba7c129d91.jpg: 1024x1024 1 0, 219.0ms\n",
      "Speed: 6.1ms preprocess, 219.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/9ecbd17d-454bdc9e-e7d9-4e54-9802-812776cbfc4c.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 4.5ms preprocess, 219.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/a0739401-521bd12b-f502-40d9-a2c3-15e30d4ecc4e.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 4.7ms preprocess, 219.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/a0c92faa-5da74632-9a8a-464c-99e8-c39b0ebba53d.jpg: 1024x1024 1 0, 218.6ms\n",
      "Speed: 5.4ms preprocess, 218.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/a4a416ba-54250778-b5d5-4b14-88d7-db2e54d09532.jpg: 1024x1024 1 0, 219.4ms\n",
      "Speed: 8.1ms preprocess, 219.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/a4c25509-4734dbe5-e39a-4ea9-b95b-74f887abd86c.png: 1024x1024 1 0, 219.5ms\n",
      "Speed: 4.9ms preprocess, 219.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/a8106b05-2d779666-7730-4f3f-a9fa-848366d44880.jpg: 1024x1024 1 0, 219.2ms\n",
      "Speed: 4.2ms preprocess, 219.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/a9cc5028-08011114-e16a-45ea-b4c0-2856ea65db3a.jpg: 1024x1024 1 0, 219.1ms\n",
      "Speed: 5.7ms preprocess, 219.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/ab232427-15590597-d37e-4f9a-923f-f6c2dd773100.jpg: 1024x1024 1 0, 220.7ms\n",
      "Speed: 6.2ms preprocess, 220.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/ae2b9cdd-5ac1ac73-96fc-42f0-8867-e299a8bb0908.jpg: 1024x1024 1 0, 219.8ms\n",
      "Speed: 4.7ms preprocess, 219.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/afeda6b8-06f9333e-d08c-48af-bd5a-7fd542e70e88.jpg: 1024x1024 1 0, 219.6ms\n",
      "Speed: 6.0ms preprocess, 219.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/b0aee9df-7ec9ed58-2258-4dc2-85af-e889f75e5fe6.jpg: 1024x1024 1 0, 218.8ms\n",
      "Speed: 6.8ms preprocess, 218.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/b2931789-9918ecca-cb63-4def-a7b1-ec0ab71b20bc.jpg: 1024x1024 1 0, 1 1, 1 2, 1 3, 222.3ms\n",
      "Speed: 6.0ms preprocess, 222.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/b3123ec8-8b2956a2-1183-4b7c-b8f1-e4535020b516.jpg: 1024x1024 1 0, 218.6ms\n",
      "Speed: 4.6ms preprocess, 218.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/b7089ffe-4cff2a62-6fe3-470e-b651-fd7fefcdd066.jpg: 1024x1024 1 0, 218.9ms\n",
      "Speed: 4.8ms preprocess, 218.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/b8e0f5ab-3f750e30-3b7b-4eae-aee7-60f6bec36ffe.png: 1024x1024 1 0, 218.7ms\n",
      "Speed: 5.2ms preprocess, 218.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/b961aac6-03319734-b8dc-4096-abf4-ac41c2304c15.jpg: 1024x1024 1 0, 1 1, 220.2ms\n",
      "Speed: 6.0ms preprocess, 220.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/bb14a248-0d355874-a211-4489-be08-c028b44b794f.jpg: 1024x1024 1 0, 219.2ms\n",
      "Speed: 5.3ms preprocess, 219.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/bc8f00a1-14743446-f832-4d1a-8539-22d201495035.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 6.1ms preprocess, 219.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/bdfc9567-6402a95f-578a-4d30-b9a9-ca5488082088.jpg: 1024x1024 1 0, 1 1, 220.3ms\n",
      "Speed: 4.2ms preprocess, 220.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/be06994c-96ed6690-77ef-4e1a-b99c-79223b588df7.jpg: 1024x1024 1 0, 219.9ms\n",
      "Speed: 6.1ms preprocess, 219.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/c5146f4f-23e69860-6777-4b3a-b1ed-365660144e7d.jpg: 1024x1024 1 0, 219.0ms\n",
      "Speed: 4.1ms preprocess, 219.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/cb051d9d-154ee843-bfdc-49e1-9b49-fc99a72f202f.jpg: 1024x1024 1 0, 218.9ms\n",
      "Speed: 4.0ms preprocess, 218.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/cb7c5c66-59c72e15-7d77-4998-a86a-80820bb8cc72.jpg: 1024x1024 1 0, 220.5ms\n",
      "Speed: 5.0ms preprocess, 220.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/cc0592d5-3d8fb8e3-2560-4fe2-85fa-379e232946de.jpg: 1024x1024 1 0, 219.0ms\n",
      "Speed: 6.6ms preprocess, 219.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/cc71313d-dd460d4f-5630-4f8d-a05c-bef6cc46cb17.png: 1024x1024 1 0, 219.8ms\n",
      "Speed: 4.1ms preprocess, 219.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/cce53bac-66613fb1-846c-4563-a6c5-94ab65921bf8.png: 1024x1024 1 0, 219.0ms\n",
      "Speed: 4.3ms preprocess, 219.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/cecf9ed9-66814b5f-959c-4fbc-ab91-231aa65c621b.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 4.8ms preprocess, 219.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/d62b93e0-04b1de90-d55e-42d9-996c-b2fb4f315aac.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 4.1ms preprocess, 219.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/d6a58375-baf3c9fd-5055-480e-adec-e5488a64f7da.png: 1024x1024 1 0, 219.1ms\n",
      "Speed: 5.5ms preprocess, 219.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/d845018c-213fa942-1fae-4d7d-ac28-8c0e4fdc6a1e.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 5.2ms preprocess, 219.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/d85e08e1-532cd2a7-be7c-4b9f-b920-126cf0634c3b.jpg: 1024x1024 1 0, 1 1, 220.0ms\n",
      "Speed: 6.6ms preprocess, 220.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/d885d49f-a4c1e045-ec2e-4239-b408-199301eceb92.jpg: 1024x1024 1 0, 219.4ms\n",
      "Speed: 6.6ms preprocess, 219.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/da829f87-dfd8de29-c52b-4b8a-8c56-9cb08847e069.jpg: 1024x1024 1 0, 1 1, 220.1ms\n",
      "Speed: 6.4ms preprocess, 220.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/e1b37e6a-21f077df-bf37-488f-ad9d-35b8b8014c2c.jpg: 1024x1024 1 0, 219.7ms\n",
      "Speed: 4.7ms preprocess, 219.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/e66ed5e0-7af19430-9f18-4ffd-af67-1688f6a0dc01.jpg: 1024x1024 1 0, 219.7ms\n",
      "Speed: 4.2ms preprocess, 219.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/e725e4af-eb4a0469-91aa-4271-891a-6eea41c3ba73.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 5.5ms preprocess, 219.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/e7db36bd-9521782e-fa4a-4f7b-83b4-ac3ef705505e.jpg: 1024x1024 1 0, 219.5ms\n",
      "Speed: 4.7ms preprocess, 219.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/e847dd0b-acae7fb0-77e0-4d28-9bc3-8a2396783ade.jpg: 1024x1024 1 0, 1 1, 220.3ms\n",
      "Speed: 4.7ms preprocess, 220.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/ed961044-34da8e07-4d86-4179-a31f-5fca72e179a3.jpg: 1024x1024 1 0, 219.6ms\n",
      "Speed: 6.1ms preprocess, 219.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/f1579626-93b73450-9fb3-4dff-81bb-cefb27d9c33f.jpg: 1024x1024 1 0, 219.8ms\n",
      "Speed: 5.6ms preprocess, 219.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/f27e5eba-bcddddf5-84dc-4907-b8cc-d3a40b58fe32.jpg: 1024x1024 1 0, 219.8ms\n",
      "Speed: 4.6ms preprocess, 219.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/f67243a1-6ad4cd55-c0be-4a65-aff4-bc9b11f70051.png: 1024x1024 1 0, 219.4ms\n",
      "Speed: 5.4ms preprocess, 219.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/faa41500-1340437c-660d-44e5-b9c1-96261582490e.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 6.2ms preprocess, 219.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/fb674256-18b45c14-f92e-4d7c-ad34-4c97318bbc53.jpg: 1024x1024 1 0, 219.3ms\n",
      "Speed: 5.5ms preprocess, 219.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/kaggle_v0/screwdriver/images/fe13c32a-79d68fc1-a7b6-4a96-99ee-1b653e02b17d.jpg: 1024x1024 1 0, 220.6ms\n",
      "Speed: 4.4ms preprocess, 220.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(f'../data/raw/{project_name}/cut_and_paste_root/') if not os.path.exists(f'../data/raw/{project_name}/cut_and_paste_root/') else None\n",
    "os.system(f\"cp {f'../data/raw/{project_name}/classes.txt'} {f'../data/raw/{project_name}/cut_and_paste_root/'}\")\n",
    "for class_dir, output_dir in list(zip(class_dirs, output_dirs)):\n",
    "    segment_images_from_folder_bbox(class_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd5dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of background images : 8128\n",
      "List of distractor files collected: []\n",
      "../data/processed/kaggle_v0/cut_and_paste_data/cut_and_paste.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python Cut-and-Paste/dataset_generator.py --scale --rotation --num 1 ../data/raw/{project_name}/cut_and_paste_root ../data/processed/{project_name}/cut_and_paste_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7b0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(1920, 2560, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get image size in bytes\n",
    "print(cv2.imread('../data/processed/screwdriver_kaggle/cut_and_paste_data/train/images/1_box.jpg').shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
