{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef922d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import SAM\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126924a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class folders should be organized as follows:\n",
    "#\n",
    "# raw/\n",
    "# └── imgs_to_mask/\n",
    "#     ├── darknet/\n",
    "#     │   ├── 1.txt\n",
    "#     │   └── ...\n",
    "#     └── images/\n",
    "#         ├── 1.jpg\n",
    "#         └── ...\n",
    "\n",
    "# Darknet files should have the following format:\n",
    "# class_name x_center y_center width height\n",
    "#\n",
    "# e.g.\n",
    "# Screwdriver 0.5 0.5 0.2 0.2\n",
    "\n",
    "name = 'screwdriver'\n",
    "class_folder = f'../data/raw/{name}/'\n",
    "output_dir = f'../data/raw/{name}_masked'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d79286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh_to_bbox(x, y, w, h):\n",
    "    \"\"\"\n",
    "    Convert (x, y, w, h) to (x1, y1, x2, y2) format.\n",
    "    \"\"\"\n",
    "    x1 = x\n",
    "    y1 = y\n",
    "    x2 = x + w\n",
    "    y2 = y + h\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def segment_images_from_folder_bbox(folder_path):\n",
    "    \"\"\"\n",
    "    Segments images in the specified folder using the SAM model with bbox information.\n",
    "    Assumes folder_path contains two folders: 'images' and 'darknet'.\n",
    "    Each image in 'images' should have a corresponding label file in 'darknet' with\n",
    "    bounding box information in the format: x y w h (where x, y are the\n",
    "    top-left corner coordinates and w, h are the width and height of the bounding box).\n",
    "    \"\"\"\n",
    "    model = SAM(\"sam2.1_b.pt\")\n",
    "    \n",
    "    for image_path, bbox_path in zip(sorted(glob.glob(os.path.join(folder_path, 'images', '*.jpg'))), \n",
    "                                     sorted(glob.glob(os.path.join(folder_path, 'darknet', '*.txt')))):\n",
    "        x, y, w, h = 0, 0, 0, 0\n",
    "        image_dimensions = plt.imread(image_path).shape\n",
    "        if sum([1 for line in open(bbox_path) if line.strip()]) != 1:\n",
    "            print(f\"There should be exactly one line in {bbox_path}.\")\n",
    "            continue\n",
    "\n",
    "        with open(bbox_path, 'r') as f:\n",
    "            line = f.readline().strip()\n",
    "            if line:\n",
    "                label = float(line.split()[0])  # Read the class label (first element)\n",
    "                x, y, w, h = map(float, line.split()[1:5]) # Bounding box coordinates\n",
    "                x, y, w, h = int(x * image_dimensions[1]), int(y * image_dimensions[0]), int(w * image_dimensions[1]), int(h * image_dimensions[0])\n",
    "                x = x - w // 2\n",
    "                y = y - h // 2\n",
    "\n",
    "        # Predict segmentation using the SAM model with bounding box\n",
    "        results = model(image_path, bboxes=xywh_to_bbox(x, y, w, h))\n",
    "        for result in results:\n",
    "            # Display the image with the segmentation mask\n",
    "            # result.show()\n",
    "\n",
    "            # Access the masks\n",
    "            masks = results[0].masks\n",
    "\n",
    "            # Assuming single class segmentation for simplicity, adjust as needed\n",
    "            mask = masks[0].data.squeeze().cpu().numpy()  # For multi-class, iterate over masks\n",
    "            mask = mask.astype(np.uint8) # Convert mask to uint8 if needed)\n",
    "            mask = cv2.resize(mask, (image_dimensions[1], image_dimensions[0]))\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (image_dimensions[1], image_dimensions[0]))\n",
    "            \n",
    "            # Negate the mask and mask the image\n",
    "            negative_mask = 1-mask\n",
    "            negative_image = cv2.bitwise_not(image)\n",
    "            negative_image = cv2.bitwise_and(negative_image, negative_image, mask=mask)\n",
    "            masked_image = cv2.bitwise_not(negative_image)\n",
    "            \n",
    "            # Uncomment to see the negated masks\n",
    "            # plt.imshow(negative_mask, cmap='gray')\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            # Uncomment to plot the masked images\n",
    "            # plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))\n",
    "            # plt.axis('off')\n",
    "            # plt.show()\n",
    "\n",
    "            os.mkdir(output_dir) if not os.path.exists(output_dir) else None\n",
    "            cv2.imwrite(os.path.join(output_dir, os.path.basename(image_path)), image)\n",
    "            # cv2.imwrite(os.path.join(output_dir, os.path.basename(image_path).split('.')[0] + '_masked.jpg'), masked_image)\n",
    "            cv2.imwrite(os.path.join(output_dir, os.path.basename(image_path).split('.')[0] + '_mask.png'), negative_mask*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97bbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/000872c905a57b65.jpg: 1024x1024 1 0, 116.5ms\n",
      "Speed: 2.5ms preprocess, 116.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/00d9a083e1cba929.jpg: 1024x1024 1 0, 99.3ms\n",
      "Speed: 2.5ms preprocess, 99.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/01e80d7cf80f3921.jpg: 1024x1024 1 0, 98.3ms\n",
      "Speed: 2.6ms preprocess, 98.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/02a90407e6bf3ef8.jpg: 1024x1024 1 0, 99.7ms\n",
      "Speed: 2.5ms preprocess, 99.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/039d98c90d183417.jpg: 1024x1024 1 0, 99.2ms\n",
      "Speed: 2.5ms preprocess, 99.2ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/05c875fdc13a93cb.jpg: 1024x1024 1 0, 99.6ms\n",
      "Speed: 2.5ms preprocess, 99.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/087c92920936e155.jpg: 1024x1024 1 0, 99.5ms\n",
      "Speed: 2.6ms preprocess, 99.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/0cb9988fa613635b.jpg: 1024x1024 1 0, 99.1ms\n",
      "Speed: 2.5ms preprocess, 99.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/107aabf5630e9daf.txt.\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/134f5428710fad6b.jpg: 1024x1024 1 0, 99.8ms\n",
      "Speed: 2.5ms preprocess, 99.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/1f10b3e18c251566.txt.\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/274112131556f171.jpg: 1024x1024 1 0, 99.4ms\n",
      "Speed: 2.6ms preprocess, 99.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/27753d996a207805.jpg: 1024x1024 1 0, 99.5ms\n",
      "Speed: 2.6ms preprocess, 99.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/27fe462517cc2469.jpg: 1024x1024 1 0, 99.8ms\n",
      "Speed: 2.5ms preprocess, 99.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/34e4a5693e3a6501.jpg: 1024x1024 1 0, 99.2ms\n",
      "Speed: 2.5ms preprocess, 99.2ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/38cf55592ebb90d7.jpg: 1024x1024 1 0, 99.7ms\n",
      "Speed: 2.7ms preprocess, 99.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/3dcf977dd79ecc0d.txt.\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/4362aebc502d522b.jpg: 1024x1024 1 0, 99.6ms\n",
      "Speed: 2.7ms preprocess, 99.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/479949d71534d9ab.txt.\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/481f14efd2b4236a.jpg: 1024x1024 1 0, 99.3ms\n",
      "Speed: 2.6ms preprocess, 99.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/4a78838bf777e9c1.jpg: 1024x1024 1 0, 99.6ms\n",
      "Speed: 2.5ms preprocess, 99.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/66a3beb56e4ca812.jpg: 1024x1024 1 0, 99.4ms\n",
      "Speed: 2.5ms preprocess, 99.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/6b7b9358937fb87a.jpg: 1024x1024 1 0, 99.4ms\n",
      "Speed: 2.6ms preprocess, 99.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/7748c1a164e026a1.jpg: 1024x1024 1 0, 99.4ms\n",
      "Speed: 2.6ms preprocess, 99.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/7bddd8020e088b07.jpg: 1024x1024 1 0, 99.5ms\n",
      "Speed: 2.6ms preprocess, 99.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/80ad1997b7c1fc38.txt.\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/815c60dd718f4af7.jpg: 1024x1024 1 0, 99.3ms\n",
      "Speed: 2.6ms preprocess, 99.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/85e18911d236590b.jpg: 1024x1024 1 0, 100.1ms\n",
      "Speed: 2.5ms preprocess, 100.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/8abe387edad1ab14.jpg: 1024x1024 1 0, 99.7ms\n",
      "Speed: 2.6ms preprocess, 99.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/8d0f2635a4debf71.jpg: 1024x1024 1 0, 99.7ms\n",
      "Speed: 2.7ms preprocess, 99.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/96f329e042e6adaf.jpg: 1024x1024 1 0, 99.6ms\n",
      "Speed: 2.7ms preprocess, 99.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/a6cae0a6ad7a8850.jpg: 1024x1024 1 0, 99.8ms\n",
      "Speed: 2.7ms preprocess, 99.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/a8b3e60fa28d7b18.jpg: 1024x1024 1 0, 100.2ms\n",
      "Speed: 2.6ms preprocess, 100.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/c1fb638b9938a284.jpg: 1024x1024 1 0, 99.5ms\n",
      "Speed: 2.6ms preprocess, 99.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/e374045a80e99928.txt.\n",
      "There should be exactly one line in ../data/raw/screwdriver/darknet/e3bfb71bef1818af.txt.\n",
      "\n",
      "image 1/1 /home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/../data/raw/screwdriver/images/f1f0e4592b32ad14.jpg: 1024x1024 1 0, 99.3ms\n",
      "Speed: 2.5ms preprocess, 99.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "segment_images_from_folder_bbox(class_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad41c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../data/cut_and_paste_root/{name}/\"):\n",
    "    os.makedirs(f\"../data/cut_and_paste_root/{name}\")\n",
    "os.system(f\"cp {os.path.join(output_dir, '*')} ../data/cut_and_paste_root/{name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd5dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of background images : 8124\n",
      "List of distractor files collected: []\n",
      "Working on ../data/processed/screwdriver/images/1_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/2_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/3_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/4_none.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:373: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  backgrounds[i] = Image.fromarray(background_array, 'RGB')\n",
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:373: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  backgrounds[i] = Image.fromarray(background_array, 'RGB')\n",
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:373: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  backgrounds[i] = Image.fromarray(background_array, 'RGB')\n",
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:67: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  blurred_img = Image.fromarray(blurred_img, 'RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ../data/processed/screwdriver/images/5_none.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:67: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  blurred_img = Image.fromarray(blurred_img, 'RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ../data/processed/screwdriver/images/6_none.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:67: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  blurred_img = Image.fromarray(blurred_img, 'RGB')\n",
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:373: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  backgrounds[i] = Image.fromarray(background_array, 'RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ../data/processed/screwdriver/images/7_none.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/decla_5ay7wb/RIPS25-AnalogDevices-ObjectDetection/src/Cut-and-Paste/dataset_generator.py:67: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  blurred_img = Image.fromarray(blurred_img, 'RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ../data/processed/screwdriver/images/8_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/9_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/10_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/11_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/12_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/13_none.jpg\n",
      "Working on ../data/processed/screwdriver/images/14_none.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python Cut-and-Paste/dataset_generator.py --scale --rotation --num 1 ../data/cut_and_paste_root ../data/processed/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55d7b0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2560, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get image size in bytes\n",
    "print(cv2.imread('data/cut_and_paste_croissants/images/8_poisson.jpg').shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
